"""
è®°å¿†é›†æˆæ¨¡å— - Memory Integration Module

å°† LoopEngine äº‹ä»¶è‡ªåŠ¨åˆ†å‘åˆ° L1-L5 äº”å±‚è®°å¿†æ¶æ„ï¼š
- L1: RawEventStore - åŸå§‹äº‹ä»¶å­˜å‚¨
- L2: EventRelationStore - äº‹ä»¶å…³ç³»å›¾
- L3: EventEmbeddingStore - è¯­ä¹‰åµŒå…¥
- L4: SummaryStore - æ—¶é—´æ‘˜è¦
- L5: CapabilityMemory - èƒ½åŠ›æå–

è®¾è®¡åŸåˆ™ï¼š
1. æœ€å°ä¾µå…¥ - ä¸ä¿®æ”¹ LoopEngine æ ¸å¿ƒé€»è¾‘
2. å¼‚æ­¥ä¼˜å…ˆ - è®°å¿†æ“ä½œåœ¨åå°æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»é“¾è·¯
3. å¯é…ç½® - å„å±‚å¯ç‹¬ç«‹å¯ç”¨/ç¦ç”¨
4. ä¼˜é›…é™çº§ - æŸå±‚å¤±è´¥ä¸å½±å“å…¶ä»–å±‚å’Œä¸»é“¾è·¯
"""
import asyncio
import logging
import time
import uuid
from typing import Dict, Any, Optional, List, Set
from dataclasses import dataclass, field
from datetime import datetime
from collections import deque

# UnifiedMemoryStore is defined in __init__.py
from . import UnifiedMemoryStore
from ..events.events import Event, EventTypes, BusinessEventTypes
from ..events.backend import MessageBusBackend

logger = logging.getLogger(__name__)


@dataclass
class MemoryIntegrationConfig:
    """è®°å¿†é›†æˆé…ç½®"""

    # L1-L5 å±‚çº§å¯ç”¨å¼€å…³
    enable_l1_raw: bool = True
    enable_l2_relations: bool = True
    enable_l3_embeddings: bool = True
    enable_l4_summaries: bool = True
    enable_l5_capabilities: bool = True

    # L3 åµŒå…¥ç”Ÿæˆé…ç½®
    async_embeddings: bool = True
    embedding_queue_size: int = 100

    # L2 å…³ç³»æå–é…ç½®
    auto_extract_relations: bool = True

    # L4 æ‘˜è¦ç”Ÿæˆé…ç½®
    summary_interval_minutes: int = 60
    auto_generate_summaries: bool = True

    # L5 èƒ½åŠ›æå–é…ç½®
    capability_min_attempts: int = 3
    capability_min_success_rate: float = 0.7
    capability_blacklist_threshold: float = 0.3
    capability_blacklist_min_attempts: int = 5

    # ========== L1 äº‹ä»¶è¿‡æ»¤é…ç½® ==========
    # è¦è®°å½•çš„äº‹ä»¶ç±»å‹ï¼ˆç™½åå•ï¼‰
    l1_event_whitelist: Set[str] = field(default_factory=lambda: {
        EventTypes.USER_MESSAGE,      # ç”¨æˆ·è¾“å…¥ â†’ è½¬æ¢ä¸º USER_INPUT
        EventTypes.ACTION_EXECUTED,   # åŠ¨ä½œæ‰§è¡Œ â†’ è½¬æ¢ä¸º AI_RESPONSE æˆ– TOOL_INVOKED
        EventTypes.TASK_COMPLETED,    # ä»»åŠ¡å®Œæˆ
        EventTypes.TASK_FAILED,       # ä»»åŠ¡å¤±è´¥
        EventTypes.ERROR_OCCURRED,    # åªè®°å½• level=ERROR çš„ä¸¥é‡é”™è¯¯
    })

    # è¦è¿‡æ»¤çš„äº‹ä»¶ç±»å‹ï¼ˆé»‘åå•ï¼‰- LoopEngine å†…éƒ¨äº‹ä»¶
    l1_event_blacklist: Set[str] = field(default_factory=lambda: {
        EventTypes.PERCEPTION_RECEIVED,
        EventTypes.PERCEPTION_PROCESSED,
        EventTypes.EXPERIENCE_STORED,
        EventTypes.LOOP_STARTED,
        EventTypes.LOOP_COMPLETED,
        EventTypes.LOOP_PAUSED,
        EventTypes.LOOP_RESUMED,
        EventTypes.LOOP_PHASE_STARTED,
        EventTypes.LOOP_PHASE_COMPLETED,
        EventTypes.AGENT_STARTED,
        EventTypes.AGENT_STOPPED,
        EventTypes.STATE_CHANGED,
        EventTypes.CAPABILITY_CREATED,
        EventTypes.CAPABILITY_UPDATED,
        EventTypes.HEALTH_WARNING,
        EventTypes.HANDLER_FAILED,
        EventTypes.TASK_CREATED,
        EventTypes.TASK_ASSIGNED,
        EventTypes.TASK_STARTED,
    })

    # åªè®°å½•ä¸¥é‡é”™è¯¯ï¼ˆlevel >= ERRORï¼‰
    l1_error_min_level: int = 3  # EventLevel.ERROR = 3

    # æ˜¯å¦å¯ç”¨äº‹ä»¶ç±»å‹è½¬æ¢ï¼ˆUSER_MESSAGE â†’ USER_INPUTï¼‰
    l1_enable_event_transform: bool = True

    # è®¢é˜…çš„äº‹ä»¶ç±»å‹ï¼ˆä¿æŒåŸè®¢é˜…æ–¹å¼ï¼‰
    subscribed_events: Set[str] = field(default_factory=lambda: {
        EventTypes.USER_MESSAGE,
        EventTypes.PERCEPTION_RECEIVED,
        EventTypes.PERCEPTION_PROCESSED,
        EventTypes.ACTION_EXECUTED,
        EventTypes.EXPERIENCE_STORED,
        EventTypes.TASK_COMPLETED,
        EventTypes.ERROR_OCCURRED,
    })


class MemoryIntegrationModule:
    """
    è®°å¿†ç³»ç»Ÿé›†æˆæ¨¡å—

    ä½œä¸ºäº‹ä»¶è®¢é˜…è€…ï¼Œæ¥æ”¶ LoopEngine å‘å¸ƒçš„äº‹ä»¶å¹¶åˆ†å‘åˆ°å„è®°å¿†å±‚ã€‚
    """

    def __init__(
        self,
        unified_memory: UnifiedMemoryStore,
        message_bus: MessageBusBackend,
        config: MemoryIntegrationConfig = None,
    ):
        """
        åˆå§‹åŒ–è®°å¿†é›†æˆæ¨¡å—

        Args:
            unified_memory: ç»Ÿä¸€è®°å¿†å­˜å‚¨å®ä¾‹
            message_bus: æ¶ˆæ¯æ€»çº¿
            config: é›†æˆé…ç½®
        """
        self.unified_memory = unified_memory
        self.message_bus = message_bus
        self.config = config or MemoryIntegrationConfig()

        # çŠ¶æ€ç®¡ç†
        self._running = False
        self._subscription_ids: List[str] = []

        # L3 å¼‚æ­¥åµŒå…¥å¤„ç†
        self._embedding_queue: asyncio.Queue = None
        self._embedding_task: asyncio.Task = None
        self._embedding_event_ids: Set[str] = set()  # ç”¨äºå»é‡

        # L4 å®šæœŸæ‘˜è¦ç”Ÿæˆ
        self._summary_task: asyncio.Task = None

        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            "events_received": 0,
            "events_processed": 0,
            "events_failed": 0,
            "l1_stored": 0,
            "l1_filtered": 0,  # æ–°å¢ï¼šè¢«è¿‡æ»¤çš„äº‹ä»¶æ•°
            "l2_relations_extracted": 0,
            "l3_embeddings_generated": 0,
            "l4_summaries_generated": 0,
            "l5_capabilities_extracted": 0,
        }

        # ç›¸å…³äº‹ä»¶è¿½è¸ªï¼ˆç”¨äº L2 å…³ç³»æå–ï¼‰
        self._correlation_tracker: Dict[str, List[str]] = {}

        logger.info("MemoryIntegrationModule initialized")

    async def start(self):
        """å¯åŠ¨è®°å¿†é›†æˆæ¨¡å—"""
        if self._running:
            logger.warning("MemoryIntegrationModule already running")
            return

        self._running = True
        logger.info("Starting MemoryIntegrationModule...")

        # åˆå§‹åŒ– L3 åµŒå…¥é˜Ÿåˆ—
        if self.config.enable_l3_embeddings and self.config.async_embeddings:
            self._embedding_queue = asyncio.Queue(
                maxsize=self.config.embedding_queue_size
            )
            self._embedding_task = asyncio.create_task(
                self._embedding_processor()
            )
            logger.info("L3 embedding processor started")

        # å¯åŠ¨ L4 å®šæœŸæ‘˜è¦ç”Ÿæˆ
        if self.config.enable_l4_summaries and self.config.auto_generate_summaries:
            self._summary_task = asyncio.create_task(
                self._summary_generator()
            )
            logger.info("L4 summary generator started")

        # è®¢é˜…äº‹ä»¶
        await self._subscribe_to_events()

        logger.info("MemoryIntegrationModule started successfully")

    async def stop(self):
        """åœæ­¢è®°å¿†é›†æˆæ¨¡å—"""
        if not self._running:
            return

        logger.info("Stopping MemoryIntegrationModule...")
        self._running = False

        # å–æ¶ˆè®¢é˜…
        await self._unsubscribe_from_events()

        # åœæ­¢ L3 åµŒå…¥å¤„ç†å™¨
        if self._embedding_task:
            self._embedding_task.cancel()
            try:
                await self._embedding_task
            except asyncio.CancelledError:
                pass
            logger.info("L3 embedding processor stopped")

        # åœæ­¢ L4 æ‘˜è¦ç”Ÿæˆå™¨
        if self._summary_task:
            self._summary_task.cancel()
            try:
                await self._summary_task
            except asyncio.CancelledError:
                pass
            logger.info("L4 summary generator stopped")

        # æŒä¹…åŒ–æ•°æ®
        await self._persist_all()

        logger.info("MemoryIntegrationModule stopped")

    async def _subscribe_to_events(self):
        """è®¢é˜… LoopEngine äº‹ä»¶"""
        for event_type in self.config.subscribed_events:
            try:
                subscription_id = await self.message_bus.subscribe(
                    event_type=event_type,
                    handler=self._handle_event,
                    propagation_mode="broadcast",
                )
                self._subscription_ids.append(subscription_id)
                logger.info(f"Subscribed to {event_type} | ID: {subscription_id}")
            except Exception as e:
                logger.error(f"Failed to subscribe to {event_type}: {e}")

    async def _unsubscribe_from_events(self):
        """å–æ¶ˆè®¢é˜…äº‹ä»¶"""
        for subscription_id in self._subscription_ids:
            try:
                await self.message_bus.unsubscribe(subscription_id)
                logger.debug(f"Unsubscribed: {subscription_id}")
            except Exception as e:
                logger.error(f"Failed to unsubscribe {subscription_id}: {e}")
        self._subscription_ids.clear()

    # ==================== L1 äº‹ä»¶è¿‡æ»¤å’Œè½¬æ¢ ====================

    def _should_store_l1_event(self, event: Event) -> bool:
        """
        åˆ¤æ–­äº‹ä»¶æ˜¯å¦åº”è¯¥å­˜å‚¨åˆ° L1

        è¿‡æ»¤é€»è¾‘ï¼š
        1. é»‘åå•ä¼˜å…ˆ - ç›´æ¥è¿‡æ»¤ LoopEngine å†…éƒ¨äº‹ä»¶
        2. é”™è¯¯äº‹ä»¶ - åªè®°å½•ä¸¥é‡é”™è¯¯ï¼ˆlevel >= ERRORï¼‰
        3. ç™½åå• - åªè®°å½•æœ‰ä»·å€¼çš„ä¸šåŠ¡äº‹ä»¶
        """
        event_type = event.type

        # é»‘åå•ä¼˜å…ˆï¼šå†…éƒ¨äº‹ä»¶ä¸è®°å½•
        if event_type in self.config.l1_event_blacklist:
            logger.debug(f"L1 filtered (blacklist): {event_type}")
            return False

        # é”™è¯¯äº‹ä»¶ï¼šåªè®°å½•ä¸¥é‡é”™è¯¯
        if event_type == EventTypes.ERROR_OCCURRED:
            level_value = event.level.value if hasattr(event.level, 'value') else event.level
            if level_value < self.config.l1_error_min_level:
                logger.debug(f"L1 filtered (error level {level_value} < {self.config.l1_error_min_level}): {event_type}")
                return False

        # ç™½åå•æ£€æŸ¥ï¼šåªè®°å½•æœ‰ä»·å€¼çš„äº‹ä»¶
        if self.config.l1_event_whitelist:
            if event_type not in self.config.l1_event_whitelist:
                logger.debug(f"L1 filtered (not in whitelist): {event_type}")
                return False

        return True

    def _transform_to_business_event(self, event: Event) -> Event:
        """
        å°†å†…éƒ¨äº‹ä»¶è½¬æ¢ä¸ºä¸šåŠ¡äº‹ä»¶

        è½¬æ¢è§„åˆ™ï¼š
        - USER_MESSAGE â†’ USER_INPUT
        - ACTION_EXECUTED (ChatResponseAction) â†’ AI_RESPONSE
        - ACTION_EXECUTED (å…¶ä»–å·¥å…·) â†’ TOOL_INVOKED
        - ERROR_OCCURRED (level >= ERROR) â†’ SYSTEM_ERROR
        """
        if not self.config.l1_enable_event_transform:
            return event

        event_type = event.type

        # USER_MESSAGE â†’ USER_INPUT
        if event_type == EventTypes.USER_MESSAGE:
            return Event(
                type=BusinessEventTypes.USER_INPUT,
                data=event.data,
                timestamp=event.timestamp,
                source=event.source,
                level=event.level,
                correlation_id=event.correlation_id,
                metadata=event.metadata,
            )

        # ACTION_EXECUTED â†’ AI_RESPONSE æˆ– TOOL_INVOKED
        elif event_type == EventTypes.ACTION_EXECUTED:
            data = event.data if isinstance(event.data, dict) else {}
            action_type = data.get("action_type", "")

            if action_type == "ChatResponseAction":
                # è½¬æ¢ä¸º AI_RESPONSE
                return Event(
                    type=BusinessEventTypes.AI_RESPONSE,
                    data={
                        "response": data.get("response", ""),
                        "response_time_ms": data.get("execution_time", 0),
                        "action_type": action_type,
                        "user_id": data.get("user_id"),
                        "session_id": data.get("session_id"),
                    },
                    timestamp=event.timestamp,
                    source="memory_integration",
                    level=event.level,
                    correlation_id=event.correlation_id,
                    metadata=event.metadata,
                )
            else:
                # å…¶ä»–åŠ¨ä½œè½¬æ¢ä¸º TOOL_INVOKED
                return Event(
                    type=BusinessEventTypes.TOOL_INVOKED,
                    data={
                        "tool_name": action_type,
                        "tool_params": data.get("params", {}),
                        "result": "success" if data.get("success", True) else "failed",
                        "execution_time_ms": data.get("execution_time", 0),
                        "error": data.get("error"),
                    },
                    timestamp=event.timestamp,
                    source="memory_integration",
                    level=event.level,
                    correlation_id=event.correlation_id,
                    metadata=event.metadata,
                )

        # ERROR_OCCURRED â†’ SYSTEM_ERRORï¼ˆä¸¥é‡é”™è¯¯ï¼‰
        elif event_type == EventTypes.ERROR_OCCURRED:
            level_value = event.level.value if hasattr(event.level, 'value') else event.level
            if level_value >= self.config.l1_error_min_level:
                data = event.data if isinstance(event.data, dict) else {}
                return Event(
                    type=BusinessEventTypes.SYSTEM_ERROR,
                    data={
                        "error_code": data.get("error_code", "UNKNOWN"),
                        "error_message": data.get("error_message", str(data.get("error", ""))),
                        "affected_user_id": data.get("user_id", ""),
                        "level": level_value,
                    },
                    timestamp=event.timestamp,
                    source="memory_integration",
                    level=event.level,
                    correlation_id=event.correlation_id,
                    metadata=event.metadata,
                )

        # å…¶ä»–äº‹ä»¶ä¸è½¬æ¢
        return event

    async def _handle_event(self, event: Event):
        """
        å¤„ç†æ¥æ”¶åˆ°çš„äº‹ä»¶

        è¿™æ˜¯ä¸»è¦çš„å›è°ƒå‡½æ•°ï¼Œç”±æ¶ˆæ¯æ€»çº¿çš„ worker åœ¨äº‹ä»¶å‘ç”Ÿæ—¶è°ƒç”¨ã€‚

        Args:
            event: äº‹ä»¶å¯¹è±¡ï¼ˆEvent ç±»å‹ï¼‰
        """
        try:
            self._stats["events_received"] += 1
            logger.info(f"ğŸ“¥ Event received | Type: {event.type} | Source: {event.source} | Correlation: {event.correlation_id[:8] if event.correlation_id else 'None'}...")

            # ä½¿ç”¨ correlation_id ä½œä¸ºäº‹ä»¶ ID
            event_id = event.correlation_id or str(uuid.uuid4())

            # è¿½è¸ª correlation_id ç”¨äºå…³ç³»æå–
            correlation_id = event.correlation_id
            if correlation_id:
                if correlation_id not in self._correlation_tracker:
                    self._correlation_tracker[correlation_id] = []
                self._correlation_tracker[correlation_id].append(event_id)

            # L1: å­˜å‚¨åŸå§‹äº‹ä»¶ï¼ˆå¸¦è¿‡æ»¤å’Œè½¬æ¢ï¼‰
            if self.config.enable_l1_raw:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å­˜å‚¨åˆ° L1
                if self._should_store_l1_event(event):
                    # è½¬æ¢ä¸ºä¸šåŠ¡äº‹ä»¶
                    business_event = self._transform_to_business_event(event)
                    await self._store_l1_event(business_event)
                else:
                    self._stats["l1_filtered"] += 1
                    logger.debug(f"L1 skipped: {event.type}")

            # L2: æå–äº‹ä»¶å…³ç³»ï¼ˆåŒæ­¥ï¼‰
            if self.config.enable_l2_relations and self.config.auto_extract_relations:
                await self._extract_l2_relations(event, event_id)

            # L3: ç”Ÿæˆè¯­ä¹‰åµŒå…¥ï¼ˆå¼‚æ­¥é˜Ÿåˆ—ï¼‰
            if self.config.enable_l3_embeddings:
                if self.config.async_embeddings:
                    await self._queue_l3_embedding(event, event_id)
                else:
                    await self._generate_l3_embedding(event, event_id)

            # L4: æ·»åŠ åˆ°æ‘˜è¦ç¼“å­˜
            if self.config.enable_l4_summaries:
                self._cache_l4_event(event)

            # L5: å¤„ç†èƒ½åŠ›æå–
            if self.config.enable_l5_capabilities:
                await self._handle_l5_capability(event)

            self._stats["events_processed"] += 1

            logger.debug(
                f"Event processed | Type: {event.type} | "
                f"ID: {event_id[:8]}..."
            )

        except Exception as e:
            self._stats["events_failed"] += 1
            logger.error(f"Failed to handle event {event.type}: {e}", exc_info=True)

    # ==================== L1: åŸå§‹äº‹ä»¶å­˜å‚¨ ====================

    async def _store_l1_event(self, event: Event):
        """å­˜å‚¨åŸå§‹äº‹ä»¶åˆ° L1 å±‚"""
        try:
            event_id = await self.unified_memory.l1_raw.store(event)
            self._stats["l1_stored"] += 1
            logger.debug(f"L1 event stored | Type: {event.type} | ID: {event_id[:8]}...")
        except Exception as e:
            logger.error(f"L1 storage failed for event type {event.type}: {e}", exc_info=True)

    # ==================== L2: äº‹ä»¶å…³ç³»æå– ====================

    async def _extract_l2_relations(self, event: Event, event_id: str):
        """æå–äº‹ä»¶å…³ç³»åˆ° L2 å±‚"""
        try:
            event_type = event.type
            correlation_id = event.correlation_id

            # è½¬æ¢ Event ä¸ºå­—å…¸æ ¼å¼å­˜å‚¨
            event_dict = {
                "id": event_id,
                "type": event_type,
                "data": event.data if isinstance(event.data, dict) else {"value": event.data},
                "timestamp": event.timestamp,
                "source": event.source,
                "correlation_id": correlation_id,
            }

            # æ·»åŠ äº‹ä»¶åˆ°ç´¢å¼•
            self.unified_memory.l2_relations.add_event(event_id, event_dict)

            # æå–åŸºäºè§„åˆ™çš„å…³ç³»
            relations_extracted = 0

            # 1. åŒ correlation_id çš„å‰åäº‹ä»¶å»ºç«‹ PRECEDE å…³ç³»
            if correlation_id and correlation_id in self._correlation_tracker:
                related_events = self._correlation_tracker[correlation_id]
                for related_id in related_events:
                    if related_id != event_id:
                        self.unified_memory.l2_relations.add_relation(
                            source_event_id=related_id,
                            target_event_id=event_id,
                            relation_type="PRECEDE",
                            confidence=0.9,
                            metadata={"correlation_id": correlation_id},
                        )
                        relations_extracted += 1

            # 2. æ ¹æ®äº‹ä»¶ç±»å‹æå–ç‰¹å®šå…³ç³»
            if event_type == EventTypes.PERCEPTION_PROCESSED:
                # æŸ¥æ‰¾åŒ correlation_id çš„ PERCEPTION_RECEIVED
                if correlation_id in self._correlation_tracker:
                    for related_id in self._correlation_tracker[correlation_id]:
                        related_event = self.unified_memory.l2_relations._events.get(related_id, {})
                        if related_event.get("type") == EventTypes.PERCEPTION_RECEIVED:
                            self.unified_memory.l2_relations.add_relation(
                                source_event_id=related_id,
                                target_event_id=event_id,
                                relation_type="TRIGGER",
                                confidence=0.95,
                            )
                            relations_extracted += 1

            elif event_type == EventTypes.EXPERIENCE_STORED:
                # å»ºç«‹ä¸å‰ç½®äº‹ä»¶çš„ FOLLOW å…³ç³»
                if correlation_id in self._correlation_tracker:
                    for related_id in self._correlation_tracker[correlation_id]:
                        if related_id != event_id:
                            self.unified_memory.l2_relations.add_relation(
                                source_event_id=related_id,
                                target_event_id=event_id,
                                relation_type="FOLLOW",
                                confidence=0.8,
                            )
                            relations_extracted += 1

            # 3. æå–åŒç”¨æˆ·/åŒä¸Šä¸‹æ–‡å…³ç³»
            user_id = self._extract_user_id_from_event(event)
            if user_id:
                # æŸ¥æ‰¾åŒç”¨æˆ·çš„å…¶ä»–äº‹ä»¶
                for other_id, other_event in self.unified_memory.l2_relations._events.items():
                    if other_id != event_id:
                        other_user = other_event.get("data", {}).get("user_id", "")
                        if other_user == user_id:
                            self.unified_memory.l2_relations.add_relation(
                                source_event_id=other_id,
                                target_event_id=event_id,
                                relation_type="SAME_USER",
                                confidence=0.7,
                                metadata={"user_id": user_id},
                            )
                            relations_extracted += 1

            if relations_extracted > 0:
                self._stats["l2_relations_extracted"] += relations_extracted

            # æŒä¹…åŒ–å…³ç³»å›¾ï¼ˆæ¯æ¬¡æœ‰æ–°å…³ç³»æ—¶ï¼‰
            if relations_extracted > 0:
                self.unified_memory.l2_relations._save_to_disk()

        except Exception as e:
            logger.error(f"L2 relation extraction failed: {e}")

    def _extract_user_id_from_event(self, event: Event) -> Optional[str]:
        """ä»äº‹ä»¶ä¸­æå–ç”¨æˆ· ID"""
        # ä» data å­—æ®µä¸­æŸ¥æ‰¾ user_id
        if isinstance(event.data, dict):
            return event.data.get("user_id")
        # ä» metadata ä¸­æŸ¥æ‰¾
        if isinstance(event.metadata, dict):
            return event.metadata.get("user_id")
        return None

    # ==================== L3: è¯­ä¹‰åµŒå…¥ç”Ÿæˆ ====================

    async def _queue_l3_embedding(self, event: Event, event_id: str):
        """å°†äº‹ä»¶æ”¾å…¥ L3 åµŒå…¥é˜Ÿåˆ—"""
        try:
            if self._embedding_queue and not self._embedding_queue.full():
                if event_id and event_id not in self._embedding_event_ids:
                    await self._embedding_queue.put(event)
                    self._embedding_event_ids.add(event_id)
        except asyncio.QueueFull:
            logger.warning("L3 embedding queue full, dropping event")
        except Exception as e:
            logger.error(f"L3 embedding queue failed: {e}")

    async def _generate_l3_embedding(self, event: Event, event_id: str):
        """ç›´æ¥ç”Ÿæˆ L3 åµŒå…¥ï¼ˆåŒæ­¥ï¼‰"""
        try:
            # æå–æ–‡æœ¬
            text = self._extract_text_from_event(event)
            if not text:
                return

            await self.unified_memory.l3_embeddings.add_event(
                event_id=event_id,
                text=text,
                metadata={"event_type": event.type},
            )
            self._stats["l3_embeddings_generated"] += 1

            # æŒä¹…åŒ–åµŒå…¥
            self.unified_memory.l3_embeddings._save_to_disk()

        except Exception as e:
            logger.error(f"L3 embedding generation failed: {e}")

    async def _embedding_processor(self):
        """
        L3 å¼‚æ­¥åµŒå…¥å¤„ç†å™¨ï¼ˆåå°ä»»åŠ¡ï¼‰

        ä»é˜Ÿåˆ—ä¸­è·å–äº‹ä»¶å¹¶ç”ŸæˆåµŒå…¥å‘é‡
        """
        logger.info("L3 embedding processor running")

        while self._running:
            try:
                # ä½¿ç”¨è¶…æ—¶é¿å…é˜»å¡
                event = await asyncio.wait_for(
                    self._embedding_queue.get(),
                    timeout=1.0
                )

                # ä½¿ç”¨ correlation_id ä½œä¸º event_id
                event_id = event.correlation_id or str(uuid.uuid4())
                await self._generate_l3_embedding(event, event_id)

                # ä»å»é‡é›†åˆä¸­ç§»é™¤
                if event_id in self._embedding_event_ids:
                    self._embedding_event_ids.remove(event_id)

            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"L3 embedding processor error: {e}")

        logger.info("L3 embedding processor stopped")

    def _extract_text_from_event(self, event: Event) -> str:
        """ä»äº‹ä»¶ä¸­æå–æ–‡æœ¬ç”¨äºåµŒå…¥"""
        parts = []

        # æ·»åŠ äº‹ä»¶ç±»å‹
        if event.type:
            parts.append(event.type)

        # æ·»åŠ æ•°æ®å†…å®¹
        data = event.data if isinstance(event.data, dict) else {}
        for key, value in data.items():
            if isinstance(value, str):
                parts.append(value)
            elif isinstance(value, (int, float, bool)):
                parts.append(f"{key}:{value}")

        return " ".join(parts) if parts else ""

    # ==================== L4: æ‘˜è¦ç¼“å­˜ ====================

    def _cache_l4_event(self, event: Event):
        """å°†äº‹ä»¶æ·»åŠ åˆ° L4 æ‘˜è¦ç¼“å­˜"""
        try:
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            event_dict = {
                "id": event.correlation_id or str(uuid.uuid4()),
                "type": event.type,
                "data": event.data if isinstance(event.data, dict) else {"value": event.data},
                "timestamp": event.timestamp,
                "source": event.source,
                "level": event.level.value if hasattr(event.level, 'value') else event.level,
                "correlation_id": event.correlation_id,
                "metadata": event.metadata,
            }
            self.unified_memory.l4_summaries.add_event(event_dict)
        except Exception as e:
            logger.error(f"L4 event caching failed: {e}")

    async def _summary_generator(self):
        """
        L4 å®šæœŸæ‘˜è¦ç”Ÿæˆå™¨ï¼ˆåå°ä»»åŠ¡ï¼‰

        æ¯éš” summary_interval_minutes è¿è¡Œä¸€æ¬¡
        """
        logger.info("L4 summary generator running")

        while self._running:
            try:
                # ç­‰å¾…æŒ‡å®šé—´éš”
                await asyncio.sleep(self.config.summary_interval_minutes * 60)

                # ç”Ÿæˆå„çº§æ‘˜è¦
                for period_type in ["hour", "day"]:
                    period_key = self.unified_memory.l4_summaries._get_period_key(
                        time.time(), period_type
                    )

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆ
                    if period_key not in self.unified_memory.l4_summaries._summaries[period_type]:
                        summary = self.unified_memory.l4_summaries.generate_summary(
                            period_type, period_key
                        )
                        if summary:
                            self._stats["l4_summaries_generated"] += 1
                            logger.info(f"Summary generated: {period_type}/{period_key}")

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"L4 summary generator error: {e}")

        logger.info("L4 summary generator stopped")

    # ==================== L5: èƒ½åŠ›æå– ====================

    async def _handle_l5_capability(self, event: Event):
        """å¤„ç† L5 èƒ½åŠ›è®°å½•å’Œæå–"""
        try:
            event_type = event.type

            # åªå¤„ç†ç‰¹å®šäº‹ä»¶ç±»å‹
            if event_type == EventTypes.TASK_COMPLETED:
                self._record_task_capability(event)
            elif event_type == EventTypes.ACTION_EXECUTED:
                self._record_action_attempt(event)

        except Exception as e:
            logger.error(f"L5 capability handling failed: {e}")

    def _record_task_capability(self, event: Event):
        """è®°å½•ä»»åŠ¡å®Œæˆåˆ°èƒ½åŠ›è®°å¿†"""
        data = event.data if isinstance(event.data, dict) else {}
        self.unified_memory.l5_capabilities.record_attempt(
            task_id=data.get("task_id", "unknown"),
            context=event.metadata or {},
            action=data.get("action", {}),
            success=data.get("success", True),
            duration=data.get("duration", 0.0),
            error=data.get("error"),
        )

    def _record_action_attempt(self, event: Event):
        """è®°å½•åŠ¨ä½œæ‰§è¡Œå°è¯•"""
        data = event.data if isinstance(event.data, dict) else {}
        action_type = data.get("action_type", "")

        # å°†åŠ¨ä½œæ‰§è¡Œè®°å½•ä¸ºä»»åŠ¡å°è¯•
        if action_type:
            self.unified_memory.l5_capabilities.record_attempt(
                task_id=f"action_{action_type}",
                context={
                    "event_type": event.type,
                    "action_type": action_type,
                },
                action={"type": action_type},
                success=data.get("success", True),
                duration=data.get("execution_time", 0.0),
                error=data.get("error"),
            )

    # ==================== æŒä¹…åŒ–å’Œç»Ÿè®¡ ====================

    async def _persist_all(self):
        """æŒä¹…åŒ–æ‰€æœ‰å±‚çº§çš„æ•°æ®"""
        try:
            # L2: ä¿å­˜å…³ç³»å›¾
            if self.config.enable_l2_relations:
                self.unified_memory.l2_relations._save_to_disk()

            # L3: ä¿å­˜åµŒå…¥
            if self.config.enable_l3_embeddings:
                self.unified_memory.l3_embeddings._save_to_disk()

            # L4: ä¿å­˜æ‘˜è¦
            if self.config.enable_l4_summaries:
                self.unified_memory.l4_summaries._save_to_disk()

            # L5: ä¿å­˜èƒ½åŠ›
            if self.config.enable_l5_capabilities:
                self.unified_memory.l5_capabilities._save_to_disk()

            logger.info("All memory layers persisted")

        except Exception as e:
            logger.error(f"Failed to persist memory layers: {e}")

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self._stats,
            "config": {
                "enable_l1_raw": self.config.enable_l1_raw,
                "enable_l2_relations": self.config.enable_l2_relations,
                "enable_l3_embeddings": self.config.enable_l3_embeddings,
                "enable_l4_summaries": self.config.enable_l4_summaries,
                "enable_l5_capabilities": self.config.enable_l5_capabilities,
                "async_embeddings": self.config.async_embeddings,
                "auto_extract_relations": self.config.auto_extract_relations,
                "summary_interval_minutes": self.config.summary_interval_minutes,
            },
            "subscription_count": len(self._subscription_ids),
            "queue_size": self._embedding_queue.qsize() if self._embedding_queue else 0,
        }

    async def generate_pending_summaries(self):
        """æ‰‹åŠ¨ç”Ÿæˆæ‰€æœ‰å¾…å¤„ç†çš„æ‘˜è¦"""
        if not self.config.enable_l4_summaries:
            return

        for period_type in ["hour", "day", "week"]:
            period_key = self.unified_memory.l4_summaries._get_period_key(
                time.time(), period_type
            )

            if period_key not in self.unified_memory.l4_summaries._summaries[period_type]:
                summary = self.unified_memory.l4_summaries.generate_summary(
                    period_type, period_key
                )
                if summary:
                    self._stats["l4_summaries_generated"] += 1

        logger.info("Pending summaries generated")


__all__ = [
    "MemoryIntegrationConfig",
    "MemoryIntegrationModule",
]
