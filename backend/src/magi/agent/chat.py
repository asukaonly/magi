"""
ChatAgent - èŠå¤©Agentå®ç°

å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œé€šè¿‡LLMç”Ÿæˆå›å¤ï¼Œé€šè¿‡WebSocketæ¨é€
éµå¾ªæ­£ç¡®çš„Agentæ¶æ„ï¼šSense-Plan-Act-Reflect
"""
import time
import logging
import re
import json
import uuid
import sqlite3
from typing import Any, Optional, Dict, List
from ..core.complete_agent import CompleteAgent
from ..core.agent import AgentConfig
from ..events.backend import MessageBusBackend
from ..llm.base import LLMAdapter
from ..llm.provider_bridge import LLMProviderBridge
from ..utils.agent_logger import get_agent_logger, log_chain_start, log_chain_step, log_chain_end
from ..utils.llm_logger import get_llm_logger, log_llm_request, log_llm_response
from ..tools.registry import ToolRegistry, tool_registry
from ..tools.selector import ToolSelector
from ..tools.context_decider import ContextDecider
from ..tools.function_calling import FunctionCallingExecutor
from ..tools.schema import ToolExecutionContext
from ..memory.self_memory import SelfMemory
from ..memory.other_memory import OtherMemory
from ..memory.behavior_evolution import SatisfactionLevel
from ..memory.emotional_state import InteractionOutcome, EngagementLevel
from ..memory.growth_memory import InteractionType
from ..memory.context_builder import Scenario
from ..memory.models import TaskBehaviorProfile
from ..utils.runtime import get_runtime_paths

logger = logging.getLogger(__name__)
agent_logger = get_agent_logger('chat')
llm_logger = get_llm_logger('chat')
TOOL_INTERACTION_EVENT_TYPE = "TOOL_INTERACTION"


def clean_tool_artifacts(text: str) -> str:
    """
    æ¸…ç†LLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨ç—•è¿¹

    ç§»é™¤ç±»ä¼¼è¿™æ ·çš„æ ¼å¼:
    - <antml:function_calls>...</antml:function_calls>
    - <antml:tool_result>...</antml:tool_result>
    - <tool_result>...</tool_result>
    - {"name": "tool", "arguments": {...}}
    - <invoke>...</invoke>

    Args:
        text: åŸå§‹LLMå“åº”

    Returns:
        æ¸…ç†åçš„å“åº”
    """
    # ç§»é™¤ function_calls æ ‡ç­¾åŠå…¶å†…å®¹
    text = re.sub(r'<antml:function_calls>.*?</antml:function_calls>', '', text, flags=re.DOTALL)

    # ç§»é™¤ tool_result æ ‡ç­¾åŠå…¶å†…å®¹
    text = re.sub(r'<antml:tool_result>.*?</antml:tool_result>', '', text, flags=re.DOTALL)
    text = re.sub(r'<tool_result>.*?</tool_result>', '', text, flags=re.DOTALL)

    # ç§»é™¤ invoke æ ‡ç­¾åŠå…¶å†…å®¹
    text = re.sub(r'<invoke>.*?</invoke>', '', text, flags=re.DOTALL)

    # ä»…ç§»é™¤â€œç‹¬å ä¸€è¡Œâ€çš„å‡½æ•°è°ƒç”¨JSONï¼Œé¿å…è¯¯åˆ æ­£å¸¸ä¸šåŠ¡JSONå†…å®¹
    cleaned_lines = []
    for line in text.splitlines():
        stripped = line.strip()
        remove_line = False
        if stripped.startswith("{") and stripped.endswith("}"):
            try:
                maybe_call = json.loads(stripped)
                remove_line = (
                    isinstance(maybe_call, dict)
                    and isinstance(maybe_call.get("name"), str)
                    and isinstance(maybe_call.get("arguments"), dict)
                    and set(maybe_call.keys()).issubset({"name", "arguments"})
                )
            except Exception:
                remove_line = False
        if not remove_line:
            cleaned_lines.append(line)
    text = "\n".join(cleaned_lines)

    # ç§»é™¤å‰©ä½™çš„ç©ºè¡Œï¼ˆè¶…è¿‡2ä¸ªè¿ç»­æ¢è¡Œï¼‰
    text = re.sub(r'\n{3,}', '\n\n', text)

    return text.strip()


class ChatAgent(CompleteAgent):
    """
    èŠå¤©Agent - å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤

    æ¶æ„æµç¨‹ï¼š
    1. Sense - ä»UserMessageSensorè·å–ç”¨æˆ·æ¶ˆæ¯
    2. Plan - ProcessingModuleåˆ†ææ¶ˆæ¯ï¼Œç”Ÿæˆå“åº”è®¡åˆ’
    3. Act - æ‰§è¡ŒåŠ¨ä½œï¼šè°ƒç”¨LLMç”Ÿæˆå›å¤ï¼Œé€šè¿‡WebSocketå‘é€
    4. Reflect - ä¿å­˜å¯¹è¯å†å²åˆ°è®°å¿†
    """

    def __init__(
        self,
        config: AgentConfig,
        message_bus: MessageBusBackend,
        llm_adapter: LLMAdapter,
        memory: SelfMemory = None,
        other_memory: OtherMemory = None,
        unified_memory = None,
        memory_integration = None,
    ):
        """
        åˆå§‹åŒ–ChatAgent

        Args:
            config: Agenté…ç½®
            message_bus: æ¶ˆæ¯æ€»çº¿
            llm_adapter: LLMé€‚é…å™¨
            memory: è‡ªæˆ‘è®°å¿†ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰
            other_memory: ä»–äººè®°å¿†ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰
            unified_memory: ç»Ÿä¸€è®°å¿†å­˜å‚¨ï¼ˆå¯é€‰ï¼ŒL1-L5ï¼‰
            memory_integration: è®°å¿†é›†æˆæ¨¡å—ï¼ˆå¯é€‰ï¼‰
        """
        super().__init__(config, message_bus, llm_adapter)

        # å¯¹è¯å†å²ï¼ˆæŒ‰ user_id + session_id å­˜å‚¨ï¼‰
        self._conversation_history: dict[str, list[dict]] = {}
        self._current_session_by_user: dict[str, str] = {}
        runtime_paths = get_runtime_paths()
        self._session_state_file = runtime_paths.data_dir / "chat_sessions.json"
        self._events_db_path = runtime_paths.events_db_path

        # å·¥å…·é€‰æ‹©å™¨ï¼ˆäº”æ­¥å†³ç­–æµç¨‹ï¼‰- ä¿ç•™å…¼å®¹
        self.tool_selector = ToolSelector(
            tool_registry=tool_registry,
            llm_adapter=llm_adapter,
        )

        # ä¸Šä¸‹æ–‡å†³ç­–å™¨ - æ–°çš„å·¥å…·é€‰æ‹©æ–¹å¼
        self.context_decider = ContextDecider(
            tool_registry=tool_registry,
            llm_adapter=llm_adapter,
        )

        # å‡½æ•°è°ƒç”¨æ‰§è¡Œå™¨ - æ”¯æŒè¿ç»­å·¥å…·è°ƒç”¨
        self.function_calling_executor = FunctionCallingExecutor(
            llm_adapter=llm_adapter,
            tool_registry=tool_registry,
            skill_executor=None,  # Will set after skill_executor is initialized
            tool_result_callback=self._record_tool_interaction,
        )

        # å·¥å…·äº¤äº’å†å²ï¼ˆæŒ‰ user_id + session_id å­˜å‚¨ï¼‰
        self._tool_interactions: dict[str, list[dict]] = {}
        self._load_session_state()
        self._restore_conversation_from_events()

        # è‡ªæˆ‘è®°å¿†ç³»ç»Ÿ
        self.memory = memory

        # ä»–äººè®°å¿†ç³»ç»Ÿ
        self.other_memory = other_memory

        # ç»Ÿä¸€è®°å¿†å­˜å‚¨ï¼ˆL1-L5ï¼‰
        self.unified_memory = unified_memory

        # è®°å¿†é›†æˆæ¨¡å—
        self.memory_integration = memory_integration

        # Skill æ‰§è¡Œå™¨
        from ..skills.indexer import SkillIndexer
        from ..skills.loader import SkillLoader
        from ..skills.executor import SkillExecutor

        self._skill_indexer = SkillIndexer()
        self._skill_loader = SkillLoader(self._skill_indexer)
        self._skill_executor = SkillExecutor(self._skill_loader, llm_adapter)

        # æ›´æ–°å‡½æ•°è°ƒç”¨æ‰§è¡Œå™¨çš„skill_executor
        self.function_calling_executor.skill_executor = self._skill_executor

        # åˆå§‹åŒ– skills ç´¢å¼•
        skills = self._skill_indexer.scan_all()
        if skills:
            tool_registry.register_skill_index(skills)
            agent_logger.info(f"ğŸ“š Skills indexed: {list(skills.keys())}")

        agent_logger.info(
            f"ğŸ¤– ChatAgent initialized | Name: {config.name} | "
            f"SelfMemory: {'enabled' if memory else 'disabled'} | "
            f"OtherMemory: {'enabled' if other_memory else 'disabled'} | "
            f"UnifiedMemory: {'enabled' if unified_memory else 'disabled'} | "
            f"MemoryIntegration: {'enabled' if memory_integration else 'disabled'}"
        )

    async def execute_action(self, action: Any) -> dict:
        """
        Acté˜¶æ®µ - æ‰§è¡ŒåŠ¨ä½œ

        Args:
            action: è¦æ‰§è¡Œçš„åŠ¨ä½œï¼ˆChatResponseActionï¼‰

        Returns:
            æ‰§è¡Œç»“æœ
        """
        from ..processing.actions import ChatResponseAction

        if not isinstance(action, ChatResponseAction):
            return {"success": False, "error": "Unknown action type"}

        chain_id = action.chain_id
        user_id = action.user_id
        user_message = action.user_message
        session_id = self._resolve_session_id(user_id, action.session_id)

        log_chain_step(agent_logger, chain_id, "ACT", "Generating LLM response", "DEBUG")

        try:
            # ç”ŸæˆLLMå›å¤
            response_text = await self._generate_response(user_id, user_message, session_id)

            log_chain_step(
                agent_logger,
                chain_id,
                "ACT",
                f"Response generated | Length: {len(response_text)} chars",
                "DEBUG"
            )

            # æ¸…ç†å·¥å…·è°ƒç”¨ç—•è¿¹
            cleaned_response = clean_tool_artifacts(response_text)
            if cleaned_response != response_text:
                agent_logger.info("ğŸ§¹ Cleaned tool artifacts from response")
                response_text = cleaned_response

            # å‘é€å›å¤é€šè¿‡WebSocket
            from ..api.websocket import manager

            room = f"user_{user_id}"
            response_data = {
                "response": response_text,
                "timestamp": time.time(),
                "user_id": user_id,
                "session_id": session_id,
            }

            await manager.broadcast("agent_response", response_data, room=room)

            agent_logger.info(
                f"ğŸ“¤ Response delivered | User: {user_id} | Room: {room} | Length: {len(response_text)}"
            )

            return {
                "success": True,
                "response": response_text,
                "user_id": user_id,
                "session_id": session_id,
            }

        except Exception as e:
            agent_logger.error(f"âŒ Failed to generate response: {e}")
            return {"success": False, "error": str(e)}

    async def _generate_response(self, user_id: str, user_message: str, session_id: str) -> str:
        """
        ç”ŸæˆLLMå›å¤ï¼ˆé›†æˆå·¥å…·è°ƒç”¨å’ŒæŠ€èƒ½æ‰§è¡Œï¼‰

        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ¥ Skill è°ƒç”¨ (/skill-name)
        2. ä½¿ç”¨ä¸Šä¸‹æ–‡å†³ç­–å™¨é€‰æ‹©ç›¸å…³å·¥å…·
        3. ä½¿ç”¨å‡½æ•°è°ƒç”¨æ‰§è¡Œå™¨è¿›è¡Œè¿ç»­å·¥å…·è°ƒç”¨
        4. å°†æ‰§è¡Œç»“æœåé¦ˆç»™LLMç”Ÿæˆæœ€ç»ˆå›å¤

        Args:
            user_id: ç”¨æˆ·ID
            user_message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            LLMå›å¤
        """
        start_time = time.time()

        # è·å–å¯¹è¯å†å²
        history_key = self._history_key(user_id, session_id)
        history = self._conversation_history.get(history_key, [])

        # Step 0: æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ¥ Skill è°ƒç”¨
        skill_invocation = self._skill_executor.validate_skill_invocation(user_message)
        if skill_invocation:
            skill_name, arguments = skill_invocation
            agent_logger.info(f"ğŸ¯ Direct skill invocation | Skill: /{skill_name} | Arguments: {arguments}")

            # æ‰§è¡Œ Skill
            skill_result = await self._execute_skill(
                skill_name,
                arguments,
                user_id,
                user_message,
                history,
            )

            if skill_result["success"]:
                return skill_result["response"]
            else:
                # Skill æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                return f"Skill execution failed: {skill_result.get('error', 'Unknown error')}"

        # Step 1: ä¸Šä¸‹æ–‡å†³ç­– - é€‰æ‹©ç›¸å…³å·¥å…·
        import os
        import platform
        context = {
            "os": platform.system(),
            "os_version": platform.release(),
            "current_user": os.getenv("USER") or os.getenv("USERNAME") or "unknown",
            "home_dir": os.path.expanduser("~"),
            "current_dir": os.getcwd(),
        }

        context_decision = await self.context_decider.decide(user_message, context)
        agent_logger.info(
            f"ğŸ¯ Context decision | Intent: {context_decision.intent} | "
            f"Tools: {context_decision.tools} | Reasoning: {context_decision.reasoning}"
        )

        # Step 2: ä½¿ç”¨å‡½æ•°è°ƒç”¨æ‰§è¡Œå™¨å¤„ç†
        response_text = await self._generate_response_with_function_calling(
            user_id=user_id,
            session_id=session_id,
            user_message=user_message,
            context_decision=context_decision,
            history=history,
        )

        # è®¡ç®—ä»»åŠ¡æŒç»­æ—¶é—´
        duration = time.time() - start_time

        # ä¿å­˜åˆ°å¯¹è¯å†å²
        history.append({"role": "user", "content": user_message})
        history.append({"role": "assistant", "content": response_text})
        self._conversation_history[history_key] = history

        # è®°å½•äº¤äº’åˆ°è®°å¿†ç³»ç»Ÿ
        if self.memory:
            try:
                outcome = InteractionOutcome.SUCCESS
                await self.memory.record_interaction(
                    user_id=user_id,
                    interaction_type=InteractionType.CHAT,
                    outcome="success",
                    sentiment=0.0,
                    notes=f"Message: {user_message[:100]}..."
                )

                await self.memory.update_after_interaction(
                    outcome=outcome,
                    user_engagement=EngagementLevel.MEDIUM,
                    complexity=0.5
                )

                task_id = f"chat_{int(start_time)}_{user_id}"
                await self.memory.record_task_outcome(
                    task_id=task_id,
                    task_category=context_decision.intent,
                    user_satisfaction=SatisfactionLevel.NEUTRAL,
                    accepted=True,
                    task_complexity=0.5,
                    task_duration=duration,
                )

            except Exception as e:
                agent_logger.warning(f"Failed to record interaction: {e}")

        # æ›´æ–°ä»–äººè®°å¿†
        if self.other_memory:
            try:
                self.other_memory.update_interaction(
                    user_id=user_id,
                    interaction_type="chat",
                    outcome="positive",
                    notes=f"æ¶ˆæ¯: {user_message[:100]}{'...' if len(user_message) > 100 else ''}",
                )
            except Exception as e:
                agent_logger.warning(f"Failed to update other memory: {e}")

        return response_text

    async def _generate_response_with_function_calling(
        self,
        user_id: str,
        session_id: str,
        user_message: str,
        context_decision,
        history: list[dict],
    ) -> str:
        """
        ä½¿ç”¨å‡½æ•°è°ƒç”¨æ‰§è¡Œå™¨ç”Ÿæˆå›å¤

        Args:
            user_id: ç”¨æˆ·ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            context_decision: ä¸Šä¸‹æ–‡å†³ç­–ç»“æœ
            history: å¯¹è¯å†å²

        Returns:
            LLMå›å¤
        """
        try:
            tool_context = self._build_relevant_tool_context(
                user_id=user_id,
                session_id=session_id,
                user_message=user_message,
                intent=context_decision.intent,
            )

            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = await self._build_system_prompt(
                tool_decision=None,  # ä¸å†éœ€è¦ tool_decision
                scenario=Scenario.CHAT,
                user_id=user_id,
                task_category=context_decision.intent,
                tool_memory_context=tool_context,
            )

            # å¦‚æœæ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œç›´æ¥è°ƒç”¨LLM
            if not context_decision.tools:
                agent_logger.info("â„¹ï¸  No tools selected, using direct LLM response")

                messages = []
                for msg in history[-10:]:
                    messages.append(msg)
                messages.append({"role": "user", "content": user_message})

                response_text = await self._call_llm(
                    system_prompt,
                    messages,
                    disable_thinking=not context_decision.deep_thinking,
                )
                return clean_tool_artifacts(response_text)

            # ä½¿ç”¨å‡½æ•°è°ƒç”¨æ‰§è¡Œå™¨
            agent_logger.info(f"ğŸ”§ Using function calling with tools: {context_decision.tools}")

            response_text = await self.function_calling_executor.execute_with_tools(
                user_message=user_message,
                system_prompt=system_prompt,
                selected_tools=context_decision.tools,
                user_id=user_id,
                session_id=session_id,
                conversation_history=history,
                disable_thinking=not context_decision.deep_thinking,
                intent=context_decision.intent,
            )

            return response_text

        except Exception as e:
            agent_logger.error(f"âŒ Error in _generate_response_with_function_calling: {e}")
            import traceback
            agent_logger.error(f"Traceback: {traceback.format_exc()}")

            # Fallback: try simple LLM call
            try:
                messages = [{"role": "user", "content": user_message}]
                system_prompt = await self._build_system_prompt(
                    tool_decision=None,
                    scenario=Scenario.CHAT,
                    user_id=user_id,
                    task_category="chat",
                    tool_memory_context="",
                )
                return await self._call_llm(system_prompt, messages, disable_thinking=True)
            except Exception as e2:
                agent_logger.error(f"âŒ Fallback LLM call also failed: {e2}")
                return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def _build_system_prompt(
        self,
        tool_decision: Optional[Dict],
        scenario: str = Scenario.CHAT,
        user_id: str = None,
        task_category: str = "chat",
        tool_memory_context: str = "",
    ) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤º

        Args:
            tool_decision: å·¥å…·å†³ç­–ä¿¡æ¯
            scenario: äº¤äº’åœºæ™¯
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œç”¨äºè·å–å…³ç³»ä¿¡æ¯ï¼‰
            task_category: ä»»åŠ¡ç±»åˆ«

        Returns:
            ç³»ç»Ÿæç¤º
        """
        # å¦‚æœæœ‰è®°å¿†ç³»ç»Ÿï¼Œä½¿ç”¨äººæ ¼ä¸Šä¸‹æ–‡
        if self.memory:
            try:
                personality_context = await self.memory.build_context(
                    scenario=scenario,
                    task_category=task_category,
                    user_id=user_id,
                )
                agent_logger.info(f"ğŸ­ Personality context loaded | Length: {len(personality_context)} chars")
                if personality_context:
                    agent_logger.debug(f"ğŸ­ Context preview: {personality_context[:200]}...")
            except Exception as e:
                agent_logger.warning(f"Failed to build personality context: {e}")
                personality_context = ""
        else:
            agent_logger.warning("âš ï¸ Memory system not enabled, using default personality")
            personality_context = ""

        # åŸºç¡€æç¤ºï¼ˆä¸é‡å¤èº«ä»½ä¿¡æ¯ï¼Œidentityå·²åŒ…å«åœ¨ personality_context ä¸­ï¼‰
        base_prompt = (
            "è¯·å§‹ç»ˆä»¥ä¸Šè¿°èº«ä»½å›åº”ç”¨æˆ·ã€‚"
            "ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›å»ºè®®å’Œæ‰§è¡Œä»»åŠ¡ã€‚"
        )

        # ç»„è£…æç¤º
        if personality_context:
            full_prompt = personality_context  # å·²åŒ…å«å®Œæ•´èº«ä»½ä¿¡æ¯ï¼Œä¸å†æ·»åŠ  base_prompt
        else:
            # æ²¡æœ‰äººæ ¼ä¸Šä¸‹æ–‡æ—¶çš„é»˜è®¤æç¤º
            full_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚"
                "ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›å»ºè®®å’Œæ‰§è¡Œä»»åŠ¡ã€‚"
            )

        # æ·»åŠ å·¥å…·ç›¸å…³æç¤º
        if tool_decision and tool_decision.get("tool"):
            tool_name = tool_decision.get("tool")
            full_prompt += (
                f"\n\n[ç³»ç»Ÿæç¤º] å·²ä¸ºç”¨æˆ·è°ƒç”¨å·¥å…·: {tool_name}"
                f"\nå¦‚æœä¸‹æ–¹æœ‰å·¥å…·è°ƒç”¨ç»“æœï¼Œè¯·åŸºäºç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
                f"\nå¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ç»“æœï¼Œè¯´æ˜å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè¯·å‘ŠçŸ¥ç”¨æˆ·ã€‚"
            )

        if tool_memory_context:
            full_prompt += (
                "\n\n## Recent Tool Context\n"
                "Use these recent tool execution facts only when relevant to user's query:\n"
                f"{tool_memory_context}"
            )

        return full_prompt

    def _record_tool_interaction(self, payload: Dict[str, Any]) -> None:
        """Record tool execution facts for short-term cross-turn context."""
        user_id = payload.get("user_id")
        if not user_id:
            return
        session_id = self._resolve_session_id(user_id, payload.get("session_id"))

        success = bool(payload.get("success"))
        error_message = payload.get("error") or ""
        error_code = payload.get("error_code") or ""
        data = payload.get("data")
        data_summary = ""
        if data is not None:
            data_summary = str(data)
            if len(data_summary) > 240:
                data_summary = data_summary[:240] + "..."

        tool_name = str(payload.get("tool_name") or "unknown")
        args_text = str(payload.get("arguments") or {})
        if len(args_text) > 160:
            args_text = args_text[:160] + "..."

        combined_text = f"{tool_name} {error_code} {error_message} {data_summary} {args_text}".lower()
        tags: list[str] = []
        for keyword, tag in (
            ("weather", "weather"),
            ("å¤©æ°”", "weather"),
            ("api_key", "api_key"),
            ("api key", "api_key"),
            ("qweather", "weather_provider"),
            ("missing", "missing"),
            ("not set", "missing"),
            ("é…ç½®", "config"),
            ("ç¯å¢ƒå˜é‡", "env"),
        ):
            if keyword in combined_text:
                tags.append(tag)

        record = {
            "timestamp": time.time(),
            "intent": payload.get("intent") or "unknown",
            "tool_name": tool_name,
            "status": "success" if success else "error",
            "error_code": error_code,
            "error_message": error_message,
            "result_summary": data_summary,
            "args_summary": args_text,
            "ttl_seconds": 1800 if success else 86400,
            "tags": sorted(set(tags)),
        }

        records_key = self._history_key(user_id, session_id)
        records = self._tool_interactions.setdefault(records_key, [])
        records.append(record)
        if len(records) > 100:
            self._tool_interactions[records_key] = records[-100:]
        self._persist_tool_interaction(
            user_id=user_id,
            session_id=session_id,
            record=record,
        )

    def _persist_tool_interaction(
        self,
        user_id: str,
        session_id: str,
        record: Dict[str, Any],
    ) -> None:
        """Persist tool interaction record into event_store for restart recovery."""
        try:
            if not self._events_db_path.exists():
                return

            payload = {
                "user_id": user_id,
                "session_id": session_id,
                "record": record,
            }

            event_id = str(uuid.uuid4())
            correlation_id = str(uuid.uuid4())
            timestamp = float(record.get("timestamp", time.time()))
            conn = sqlite3.connect(str(self._events_db_path))
            cur = conn.cursor()
            cur.execute(
                """
                INSERT INTO event_store (
                    id, type, data, media_path, timestamp, source,
                    level, correlation_id, metadata, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    event_id,
                    TOOL_INTERACTION_EVENT_TYPE,
                    json.dumps(payload, ensure_ascii=False),
                    None,
                    timestamp,
                    "chat_agent",
                    1,
                    correlation_id,
                    json.dumps({}, ensure_ascii=False),
                    time.time(),
                ),
            )
            conn.commit()
            conn.close()
        except Exception as e:
            agent_logger.warning(f"Failed to persist tool interaction: {e}")

    def _build_relevant_tool_context(
        self,
        user_id: str,
        session_id: str,
        user_message: str,
        intent: str,
    ) -> str:
        """Always include recent tool errors from current session."""
        records = self._tool_interactions.get(self._history_key(user_id, session_id), [])
        if not records:
            return ""

        now = time.time()
        recent_errors: list[dict] = []
        for record in records:
            age_seconds = now - float(record.get("timestamp", now))
            ttl = int(record.get("ttl_seconds", 0))
            if ttl > 0 and age_seconds > ttl:
                continue
            if str(record.get("status", "success")) == "error":
                recent_errors.append(record)

        if not recent_errors:
            return ""

        recent_errors.sort(key=lambda item: float(item.get("timestamp", 0.0)), reverse=True)
        selected = recent_errors[:3]

        lines: list[str] = []
        for record in selected:
            status = record.get("status", "unknown")
            tool_name = record.get("tool_name", "unknown")
            if status == "error":
                error_code = record.get("error_code") or "UNKNOWN_ERROR"
                error_message = record.get("error_message") or "No error message"
                lines.append(f"- [{status}] {tool_name}: {error_code} | {error_message}")
            else:
                result_summary = record.get("result_summary") or "No result summary"
                lines.append(f"- [{status}] {tool_name}: {result_summary}")

        return "\n".join(lines)

    def _extract_query_tokens(self, text: str) -> list[str]:
        """Extract lightweight tokens for relevance matching."""
        tokens = set(re.findall(r"[a-z0-9_]{2,}", text))
        for phrase in [
            "å¤©æ°”",
            "æŠ¥é”™",
            "é”™è¯¯",
            "å¤±è´¥",
            "æ•…éšœ",
            "æ€ä¹ˆå›äº‹",
            "ä¸ºä»€ä¹ˆ",
            "ä¸ºå•¥",
            "åŸå› ",
            "é—®é¢˜",
            "é…ç½®",
            "ç¯å¢ƒå˜é‡",
            "api",
            "key",
            "æ²¡é…ç½®",
        ]:
            if phrase in text:
                tokens.add(phrase)
        return sorted(tokens)

    def _history_key(self, user_id: str, session_id: str) -> str:
        return f"{user_id}::{session_id}"

    def _resolve_session_id(self, user_id: str, session_id: Optional[str] = None) -> str:
        if session_id:
            self._current_session_by_user[user_id] = session_id
            self._save_session_state()
            return session_id
        existing = self._current_session_by_user.get(user_id)
        if existing:
            return existing
        new_id = str(uuid.uuid4())
        self._current_session_by_user[user_id] = new_id
        self._save_session_state()
        return new_id

    def get_current_session_id(self, user_id: str) -> str:
        return self._resolve_session_id(user_id)

    def create_new_session(self, user_id: str) -> str:
        new_id = str(uuid.uuid4())
        self._current_session_by_user[user_id] = new_id
        self._conversation_history.setdefault(self._history_key(user_id, new_id), [])
        self._tool_interactions.setdefault(self._history_key(user_id, new_id), [])
        self._save_session_state()
        return new_id

    def _load_session_state(self) -> None:
        try:
            if self._session_state_file.exists():
                data = json.loads(self._session_state_file.read_text(encoding="utf-8"))
                if isinstance(data, dict):
                    mapping = data.get("current_session_by_user", {})
                    if isinstance(mapping, dict):
                        self._current_session_by_user = {
                            str(k): str(v) for k, v in mapping.items() if k and v
                        }
        except Exception as e:
            agent_logger.warning(f"Failed to load session state: {e}")

    def _save_session_state(self) -> None:
        try:
            payload = {"current_session_by_user": self._current_session_by_user}
            self._session_state_file.parent.mkdir(parents=True, exist_ok=True)
            self._session_state_file.write_text(
                json.dumps(payload, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )
        except Exception as e:
            agent_logger.warning(f"Failed to save session state: {e}")

    def _restore_conversation_from_events(self) -> None:
        """Restore in-memory chat histories and tool interactions from event_store."""
        try:
            if not self._events_db_path.exists():
                return
            conn = sqlite3.connect(str(self._events_db_path))
            cur = conn.cursor()
            cur.execute(
                """
                SELECT type, data
                FROM event_store
                WHERE type IN ('USER_INPUT', 'AI_RESPONSE', ?)
                ORDER BY timestamp ASC
                LIMIT 5000
                """
                ,
                (TOOL_INTERACTION_EVENT_TYPE,)
            )
            rows = cur.fetchall()
            conn.close()
        except Exception as e:
            agent_logger.warning(f"Failed to load event_store for history restore: {e}")
            return

        restored = 0
        for event_type, raw_data in rows:
            try:
                payload = json.loads(raw_data or "{}")
            except Exception:
                continue
            user_id = payload.get("user_id")
            if not user_id:
                continue
            session_id = self._resolve_session_id(user_id, payload.get("session_id"))
            key = self._history_key(user_id, session_id)
            history = self._conversation_history.setdefault(key, [])
            if event_type == "USER_INPUT":
                content = payload.get("message", "")
                if content:
                    history.append({"role": "user", "content": str(content)})
                    restored += 1
            elif event_type == "AI_RESPONSE":
                content = payload.get("response", "")
                if content:
                    history.append({"role": "assistant", "content": str(content)})
                    restored += 1
            elif event_type == TOOL_INTERACTION_EVENT_TYPE:
                record = payload.get("record")
                if not isinstance(record, dict):
                    continue
                records = self._tool_interactions.setdefault(key, [])
                records.append(record)
                if len(records) > 100:
                    self._tool_interactions[key] = records[-100:]
        if restored:
            agent_logger.info(f"ğŸ” Restored conversation messages from event_store: {restored}")

    async def _call_llm(
        self,
        system_prompt: str,
        messages: list,
        disable_thinking: bool = True,
    ) -> str:
        """
        è°ƒç”¨LLMç”Ÿæˆå›å¤

        Args:
            system_prompt: ç³»ç»Ÿæç¤º
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            LLMå›å¤
        """
        import time
        import uuid

        # ç”Ÿæˆè¯·æ±‚ID
        request_id = str(uuid.uuid4())[:8]
        start_time = time.time()

        model_name = self.llm.model_name

        # è®°å½•è¯·æ±‚æ—¥å¿—
        log_llm_request(
            llm_logger,
            request_id=request_id,
            model=model_name,
            system_prompt=system_prompt,
            messages=messages,
            max_tokens=1000,
            temperature=0.7
        )

        try:
            provider_bridge = LLMProviderBridge(self.llm)
            response_text = await provider_bridge.chat(
                system_prompt=system_prompt,
                messages=messages,
                max_tokens=1000,
                temperature=0.7,
                disable_thinking=disable_thinking,
            )

            # æ¸…ç†å·¥å…·è°ƒç”¨ç—•è¿¹
            response_text = clean_tool_artifacts(response_text)

            # è®°å½•å“åº”æ—¥å¿—
            duration_ms = int((time.time() - start_time) * 1000)
            log_llm_response(
                llm_logger,
                request_id=request_id,
                response=response_text,
                success=True,
                duration_ms=duration_ms
            )

            return response_text

        except Exception as e:
            # è®°å½•é”™è¯¯æ—¥å¿—
            duration_ms = int((time.time() - start_time) * 1000)
            log_llm_response(
                llm_logger,
                request_id=request_id,
                response="",
                success=False,
                error=str(e),
                duration_ms=duration_ms
            )
            raise

    async def _execute_tool(
        self,
        tool_name: str,
        parameters: Dict[str, Any],
        user_id: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥å…·

        Args:
            tool_name: å·¥å…·åç§°
            parameters: å·¥å…·å‚æ•°
            user_id: ç”¨æˆ·ID

        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            # ç¡®å®šæ‰€éœ€æƒé™
            permissions = ["authenticated"]

            # æ£€æŸ¥å·¥å…·æ˜¯å¦éœ€è¦å±é™©æ“ä½œæƒé™
            tool_info = tool_registry.get_tool_info(tool_name)
            if tool_info and tool_info.get("dangerous", False):
                permissions.append("dangerous_tools")

            # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            context = ToolExecutionContext(
                agent_id=self.config.name,  # ä½¿ç”¨ Agent é…ç½®ä¸­çš„åç§°
                user_id=user_id,
                workspace="/tmp",  # ä½¿ç”¨ /tmp ä½œä¸ºé»˜è®¤å·¥ä½œç›®å½•
                env_vars={},
                permissions=permissions,
            )

            # æ‰§è¡Œå·¥å…·
            result = await tool_registry.execute(tool_name, parameters, context)

            return {
                "success": result.success,
                "data": result.data,
                "error": result.error,
                "execution_time": result.execution_time,
            }

        except Exception as e:
            agent_logger.error(f"âŒ Tool execution error: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": None,
            }

    async def _execute_skill(
        self,
        skill_name: str,
        arguments: List[str],
        user_id: str,
        user_message: str,
        conversation_history: list[dict],
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Skill

        Args:
            skill_name: Skill åç§°ï¼ˆä¸å¸¦ / å‰ç¼€ï¼‰
            arguments: å‘½ä»¤è¡Œå‚æ•°
            user_id: ç”¨æˆ·ID
            user_message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²

        Returns:
            æ‰§è¡Œç»“æœ {"success": bool, "response": str, "error": ...}
        """
        import os

        # æ„å»º Skill æ‰§è¡Œä¸Šä¸‹æ–‡
        skill_context = {
            "user_id": user_id,
            "session_id": f"session_{user_id}",
            "user_message": user_message,
            "conversation_history": conversation_history,
            "env_vars": {
                "USER": os.getenv("USER") or os.getenv("USERNAME") or "unknown",
                "HOME": os.path.expanduser("~"),
                "PWD": os.getcwd(),
                "CLAUDE_SESSION_ID": f"session_{user_id}",
                "USER_ID": user_id,
            },
        }

        try:
            # æ‰§è¡Œ Skill
            result = await self._skill_executor.execute(
                skill_name=skill_name,
                arguments=arguments,
                context=skill_context,
            )

            if result.success:
                # å¦‚æœ Skill æ‰§è¡ŒæˆåŠŸï¼Œè¿”å›å†…å®¹
                response_content = result.content or ""

                # å¦‚æœ Skill è¿”å›çš„æ˜¯æŒ‡ä»¤ï¼ˆdirect modeï¼‰ï¼Œéœ€è¦é€šè¿‡ LLM ç”Ÿæˆæœ€ç»ˆå›å¤
                if result.metadata.get("mode") == "direct":
                    # ä½¿ç”¨ Skill å†…å®¹ä½œä¸ºç³»ç»Ÿæç¤º
                    system_prompt = response_content

                    messages = []
                    # æ·»åŠ å†å²å¯¹è¯
                    for msg in conversation_history[-5:]:
                        messages.append(msg)
                    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
                    messages.append({"role": "user", "content": user_message})

                    response_text = await self._call_llm(system_prompt, messages)
                    # æ¸…ç†å·¥å…·è°ƒç”¨ç—•è¿¹
                    response_text = clean_tool_artifacts(response_text)

                    return {
                        "success": True,
                        "response": response_text,
                        "mode": "direct_with_llm",
                    }
                else:
                    # Sub-agent æ¨¡å¼ï¼Œæ¸…ç†å·¥å…·è°ƒç”¨ç—•è¿¹åè¿”å›ç»“æœ
                    response_content = clean_tool_artifacts(response_content)
                    return {
                        "success": True,
                        "response": response_content,
                        "mode": "subagent",
                    }
            else:
                return {
                    "success": False,
                    "error": result.error or "Skill execution failed",
                }

        except Exception as e:
            agent_logger.error(f"âŒ Skill execution error: {e}")
            import traceback
            agent_logger.error(f"Traceback: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
            }

    def get_conversation_history(self, user_id: str, session_id: Optional[str] = None) -> list[dict]:
        """
        è·å–å¯¹è¯å†å²

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            å¯¹è¯å†å²
        """
        active_session = self._resolve_session_id(user_id, session_id)
        return self._conversation_history.get(self._history_key(user_id, active_session), [])

    def clear_conversation_history(self, user_id: str, session_id: Optional[str] = None):
        """
        æ¸…ç©ºå¯¹è¯å†å²

        Args:
            user_id: ç”¨æˆ·ID
        """
        active_session = self._resolve_session_id(user_id, session_id)
        key = self._history_key(user_id, active_session)
        self._conversation_history[key] = []
        self._tool_interactions[key] = []
        agent_logger.info(f"ğŸ—‘ï¸ Conversation history cleared | User: {user_id} | Session: {active_session}")
